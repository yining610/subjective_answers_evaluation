{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity\n",
    "$cos(\\theta) = \\frac{A\\cdot B}{|A||B|} = \\frac{dot(A\\cdot B)}{norm(A)norm(B)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9765835979265888\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "import numpy as np\n",
    "vec1 = [4,45,3,5]\n",
    "vec2 = [3,52,12,14]\n",
    "cosine_similarity = np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Similarity\n",
    "\n",
    "$J(A,B) = \\frac{|A\\cap B|}{|A\\cup B|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jacquard similarity\n",
    "import numpy as np\n",
    "def jaccard(list1,list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "a = [0.1,2,4,2,4,5,6]\n",
    "b = [4,2,3,3,4,4,0]\n",
    "\n",
    "jaccard(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mover's Distance\n",
    "\n",
    "WMD enables us to assess the \"distance\" between two documents in a meaningful way even when they have no words in common. It uses **word2vec** vector embeddings of words.\n",
    "\n",
    "The intuition behind WMD is that we find the minimum \"traveling distance\" between documents. It is superior to BOW because WMD can take the underlying geometry into account.\n",
    "\n",
    "This method is introduced by Matt Kusner et al. in [From Word Embedding To Document Distances](http://proceedings.mlr.press/v37/kusnerb15.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Mover's Distance\n",
    "import logging # initialize logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentence_1 = \"Obama speaks to the media in Illinois\"\n",
    "sentence_2 = 'The president greets the press in Chicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\610\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "download('stopwords') # Download stopwords list\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    return [w for w in sentence.lower().split() if w not in stop_words]\n",
    "\n",
    "sentence_1 = preprocess(sentence_1)\n",
    "sentence_2 = preprocess(sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-newsgroups (18846 records): The notorious collection of approximatel...\n",
      "__testing_matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Synopsis of t...\n",
      "__testing_multipart-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Synopsis of t...\n",
      "fake-news (12999 records): News dataset, contains text and metadata...\n",
      "patent-2017 (353197 records): Patent Grant Full Text. Contains the ful...\n",
      "quora-duplicate-questions (404290 records): Over 400,000 lines of potential question...\n",
      "semeval-2016-2017-task3-subtaskA-unannotated (189941 records): SemEval 2016 / 2017 Task 3 Subtask A una...\n",
      "semeval-2016-2017-task3-subtaskBC (-1 records): SemEval 2016 / 2017 Task 3 Subtask B and...\n",
      "text8 (1701 records): First 100,000,000 bytes of plain text fr...\n",
      "wiki-english-20171001 (4924894 records): Extracted Wikipedia dump from October 20...\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import json\n",
    "info = api.info()\n",
    "# print(json.dumps(info, indent=4))\n",
    "\n",
    "# available corpora\n",
    "for corpus_name, corpus_data in sorted(info['corpora'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            corpus_name,\n",
    "            corpus_data.get('num_records', -1),\n",
    "            corpus_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__testing_word2vec-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Word vecrors ...\n",
      "conceptnet-numberbatch-17-06-300 (1917247 records): ConceptNet Numberbatch consists of state...\n",
      "fasttext-wiki-news-subwords-300 (999999 records): 1 million word vectors trained on Wikipe...\n",
      "glove-twitter-100 (1193514 records): Pre-trained vectors based on  2B tweets,...\n",
      "glove-twitter-200 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-25 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-50 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-wiki-gigaword-100 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-200 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-300 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-50 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "word2vec-google-news-300 (3000000 records): Pre-trained vectors trained on a part of...\n",
      "word2vec-ruscorpora-300 (184973 records): Word2vec Continuous Skipgram vectors tra...\n"
     ]
    }
   ],
   "source": [
    "# available models\n",
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            model_name,\n",
    "            model_data.get('num_records', -1),\n",
    "            model_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 13:44:54,200 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-19 13:44:54,201 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2022-02-19 13:44:54,201 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\", 'datetime': '2022-02-19T13:44:54.201922', 'gensim': '4.1.2', 'python': '3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042', 'event': 'created'}\n",
      "2022-02-19 13:44:54,245 : INFO : loading projection weights from C:/Users/610/gensim-data/word2vec-google-news-300/GoogleNews-vectors-negative300.bin\n",
      "2022-02-19 13:45:09,664 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:/Users/610/gensim-data/word2vec-google-news-300/GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-02-19T13:45:09.664654', 'gensim': '4.1.2', 'python': '3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# model = api.load('glove-wiki-gigaword-300')\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "model = KeyedVectors.load_word2vec_format(datapath(r\"C:/Users/610/gensim-data/word2vec-google-news-300/GoogleNews-vectors-negative300.bin\"), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R._Mazzei_fused', 0.6665399670600891),\n",
       " ('Christian_Audigier_nightclub', 0.6632695198059082),\n",
       " ('copper_alloy_garnets', 0.6343654990196228),\n",
       " ('Nelmeus', 0.6274422407150269),\n",
       " ('fiber_fusion_splicing', 0.6229819655418396),\n",
       " ('Plexiglass', 0.5858588814735413),\n",
       " ('slashing_Leonardo_DiCaprio', 0.5850011110305786),\n",
       " ('plexiglass', 0.5823022723197937),\n",
       " ('Plexiglas', 0.5803930759429932),\n",
       " (\"#Q'##_unaudited\", 0.5798528790473938)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"glass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-19 13:47:19,050 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-02-19 13:47:19,050 : INFO : built Dictionary(8 unique tokens: ['illinois', 'media', 'obama', 'speaks', 'chicago']...) from 2 documents (total 8 corpus positions)\n",
      "2022-02-19 13:47:19,051 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(8 unique tokens: ['illinois', 'media', 'obama', 'speaks', 'chicago']...) from 2 documents (total 8 corpus positions)\", 'datetime': '2022-02-19T13:47:19.051494', 'gensim': '4.1.2', 'python': '3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance = 1.0175\n"
     ]
    }
   ],
   "source": [
    "distance = model.wmdistance(sentence_1, sentence_2)\n",
    "print('distance = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b05ccce202e97ea170533ef02d00dca16ad94694ffea7539d6bdc21bb0bbc073"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
